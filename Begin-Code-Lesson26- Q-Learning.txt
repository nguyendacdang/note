Lesson 26 - Q-Learning

26.2 - What's Q? 
    - Q được viết theo 1 function 
    - Q[s,a] value của action a ở state state
    - Q[s,a] = immediate reward + discounted reward

26.5 - Update rule - Notes
    - Update Rule
        The formula for computing Q for any state-action pair <s, a>, given an experience tuple <s, a, s', r>, is:
        Q'[s, a] = (1 - α) · Q[s, a] + α · (r + γ · Q[s', argmaxa'(Q[s', a'])])

        Here:

        r = R[s, a] is the immediate reward for taking action a in state s,
        γ ∈ [0, 1] (gamma) is the discount factor used to progressively reduce the value of future rewards,
        s' is the resulting next state,
        argmaxa'(Q[s', a']) is the action that maximizes the Q-value among all possible actions a' from s', and,
        α ∈ [0, 1] (alpha) is the learning rate used to vary the weight given to new experiences compared with past Q-values.